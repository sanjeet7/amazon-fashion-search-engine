# System Architecture

## ğŸ—ï¸ **Microservices Architecture Overview**

The Amazon Fashion Search Engine follows a **microservices architecture** with clear separation of concerns, enabling independent development, deployment, and scaling of each component.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Frontend Service                           â”‚
â”‚                    (Next.js + React)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Search API Service                          â”‚
â”‚                     (FastAPI)                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Search API    â”‚   Vector Store   â”‚   Health/Stats     â”‚  â”‚
â”‚  â”‚   Endpoints     â”‚   (FAISS)        â”‚   Monitoring       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ File System / Shared Storage
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Data Pipeline Service                         â”‚
â”‚                     (Python)                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Data Ingestion  â”‚ Quality Sampling â”‚ Embedding Generationâ”‚  â”‚
â”‚  â”‚ & Validation    â”‚ & Processing     â”‚ (OpenAI API)        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External Services                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   OpenAI API    â”‚   Raw Dataset    â”‚   Processed Data   â”‚  â”‚
â”‚  â”‚  (Embeddings)   â”‚    (1.3GB)       â”‚   & Embeddings     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ **Service Responsibilities**

### 1. **Data Pipeline Service** (`services/data-pipeline/`)
**Purpose**: Batch processing for data ingestion and preparation

**Responsibilities**:
- Raw dataset analysis and validation
- Quality-based stratified sampling
- Text preparation and feature extraction
- OpenAI embedding generation with batching
- FAISS index creation and optimization
- Data caching and persistence

**Technology Stack**:
- Python 3.11+
- pandas, numpy for data processing
- OpenAI API client for embeddings
- FAISS for vector index creation
- Pydantic for data validation

**Run Mode**: Batch job (one-time or scheduled)

### 2. **Search API Service** (`services/search-api/`)
**Purpose**: High-performance search API with sub-500ms response times

**Responsibilities**:
- REST API endpoints for search operations
- Vector similarity search with FAISS
- Query enhancement using LLM
- Result ranking and filtering
- Health monitoring and statistics
- API documentation and validation

**Technology Stack**:
- FastAPI for async API framework
- FAISS for vector similarity search
- OpenAI API for query enhancement
- Pydantic for request/response models
- uvicorn for ASGI server

**Run Mode**: Long-running service

### 3. **Frontend Service** (`services/frontend/`)
**Purpose**: Modern web interface for search and product discovery

**Responsibilities**:
- User interface for search and browsing
- Real-time search with debouncing
- Product visualization and details
- Responsive design for all devices
- Error handling and fallback modes

**Technology Stack**:
- Next.js 15 with App Router
- React 19 with TypeScript
- Tailwind CSS for styling
- Lucide React for icons

**Run Mode**: Development server / Static deployment

## ğŸ”§ **Shared Components**

### **Shared Library** (`shared/`)
**Purpose**: Common code, models, and utilities across services

**Contains**:
- Pydantic data models (Product, SearchRequest, etc.)
- Configuration management
- Common utilities and helpers
- Data validation schemas
- API client interfaces

### **Infrastructure** (`infrastructure/`)
**Purpose**: Deployment, monitoring, and operational tools

**Contains**:
- Docker configurations
- Kubernetes manifests
- CI/CD pipeline configurations
- Monitoring and logging setup
- Environment configurations

## ğŸ“Š **Data Flow Architecture**

### **Data Processing Flow**
```
Raw Dataset (1.3GB) 
    â†“
Data Pipeline Service
    â”œâ”€ Dataset Analysis & Quality Assessment
    â”œâ”€ Stratified Sampling (50K products)
    â”œâ”€ Text Preparation & Feature Extraction
    â”œâ”€ Batch Embedding Generation (OpenAI API)
    â”œâ”€ FAISS Index Creation
    â””â”€ Cache to Shared Storage
    â†“
Processed Data Available for Search API
```

### **Search Request Flow**
```
User Query (Frontend)
    â†“ HTTP Request
Search API Service
    â”œâ”€ Query Validation & Enhancement (OpenAI)
    â”œâ”€ Vector Similarity Search (FAISS)
    â”œâ”€ Business Logic Filtering
    â”œâ”€ Result Ranking & Pagination
    â””â”€ Response Formatting
    â†“ HTTP Response
Frontend (Product Display)
```

## ğŸ”— **Service Communication**

### **Inter-Service Communication**
- **Frontend â†” Search API**: HTTP/REST API calls
- **Search API â†” Data Pipeline**: Shared file system / object storage
- **Services â†” External APIs**: Direct HTTP calls (OpenAI)

### **Data Storage**
- **Raw Data**: File system (`data/raw/`)
- **Processed Data**: Parquet files (`data/processed/`)
- **Vector Embeddings**: NumPy arrays with metadata
- **FAISS Index**: Serialized index files
- **Configuration**: Environment variables / config files

## ğŸš€ **Deployment Strategies**

### **Development Mode**
```bash
# Start all services locally
./scripts/start-dev.sh

# Or individually:
cd services/data-pipeline && python pipeline.py
cd services/search-api && uvicorn main:app --reload
cd services/frontend && npm run dev
```

### **Production Mode**
- **Containerized**: Each service in separate Docker containers
- **Orchestrated**: Kubernetes for service management
- **Scaled**: Horizontal scaling based on load
- **Monitored**: Health checks, metrics, and logging

## ğŸ”’ **Security & Configuration**

### **Environment Variables**
```bash
# Shared Configuration
OPENAI_API_KEY=your_openai_key
LOG_LEVEL=INFO

# Data Pipeline Service
DATA_PIPELINE_SAMPLE_SIZE=50000
DATA_PIPELINE_BATCH_SIZE=100

# Search API Service  
SEARCH_API_HOST=0.0.0.0
SEARCH_API_PORT=8000
SEARCH_API_WORKERS=4

# Frontend Service
NEXT_PUBLIC_API_URL=http://localhost:8000
```

### **Security Considerations**
- API key management and rotation
- Rate limiting and request validation
- CORS configuration for frontend
- Health check endpoints for monitoring
- Error handling without data leakage

## ğŸ“ˆ **Scalability & Performance**

### **Horizontal Scaling**
- **Data Pipeline**: Can be parallelized for larger datasets
- **Search API**: Stateless service, easily horizontally scaled
- **Frontend**: Static deployment with CDN distribution

### **Performance Optimizations**
- **Caching**: Processed data and frequent queries
- **Indexing**: Optimized FAISS configurations
- **Batching**: Efficient OpenAI API usage
- **Async**: Non-blocking I/O operations

### **Resource Requirements**
- **Data Pipeline**: CPU/memory intensive (8GB+ RAM)
- **Search API**: Low latency requirements (SSD storage)
- **Frontend**: Minimal resources (static files)

## ğŸ”„ **Development Workflow**

### **Service Independence**
- Each service can be developed independently
- Clear API contracts between services
- Independent testing and deployment
- Separate dependency management

### **Local Development**
- Mock data for faster development iterations
- Service-specific development scripts
- Hot-reload capabilities for all services
- Comprehensive logging and debugging

This architecture provides a solid foundation for production deployment while maintaining development simplicity and operational excellence. 